%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title Creation)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}  
\usepackage[T1]{fontenc} 
\usepackage[top=1cm,bottom=1cm,left=0.5cm,right=1.5cm,asymmetric]{geometry}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{subfig}
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\footrulewidth}{1pt}
\fancyhead[R]{\textit{Master MVA : }}
\fancyfoot[L]{\textit{}}
%\usepackage{unicode-math}
%\setmathfont{XITS Math}
%\setmathfont[version=setB,StylisticSet=1]{XITS Math}
\usepackage{array,multirow,makecell}
\setcellgapes{1pt}
\makegapedcells
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }b{#1}}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }b{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }b{#1}}

\pagestyle{fancy}
\renewcommand{\footrulewidth}{1pt}
\fancyfoot[L]{\textit{}}
\newcommand{\cond}{(x_i|x_{\pi_i})}

%\usepackage{caption}
%\usepackage{subcaption}


%\usepackage{unicode-math}
%\setmathfont{XITS Math}
%\setmathfont[version=setB,StylisticSet=1]{XITS Math}


%\geometry{hmargin=1.5cm,vmargin=2cm}   

\geometry{hmargin=2.5cm,vmargin=2cm}   
\begin{document}

\begin{center}

\section*{Altegrad 2015 : Final project}
\section*{Text Categorization}
\subsection*{Sammy Khalife, Oussama Ennafii, Shuyu Dong}
\subsubsection*{09/04/2015}

\end{center}

\section*{1 Bag of words}
\subsection*{Method}
\subsubsection*{Preprocessing and training}
We kept Latent semantic indexing, which performs SVD to the Document-term matrix.
The main question here was to find the number of dimensions to keep. In Reuters-21578 R8 dataset, there are 5485 samples on the train set and 2189 on the test set. Building the document term matrix and applying TF-IDF method yield features of size 14575 (total number of word). 
We kept SVM for classification following the work of Thorsten Joachims ("Text categorization with suport vector machines: Learning with many relevant features").
\subsection*{Results}
With cross-validation (10 values for C and 10 values for $\gamma$, with 10 splits over the train set, with a radius basis function kernel for the SVM), keeping a dimension of 100 after dimensionality reduction yields :~\\
~\\
Micro-averaging precision : 0.781635449977~\\
Macro-averaging precision : 0.198438628628~\\
Micro-averaging recall : 0.781635449977~\\
Macro-averaging recall : 0.242023076066~\\

\section*{2 Graphs}
\subsection*{Graph of words approach}

We subdivided the task into three stages. First, we load the data and construct the document-term matrix, we reduce its dimesions and then we aplly the learning method on it.~\\
~\\
To get a document term matrix, we use the TW-IDF measure presented in \cite{rousseau2013graph}. So we made a function $'extractGraph.py'$ that extracts a graph from a document using the $networkx$ library. This function can constructs a graph that can be weighted or not and directed or not. We can also tune in the window size through the argument $window$. That is when we introduce the function $'documentWordMatrix'$ that constructs obviously a document word matrix. In this matrix, we use the previous function to get the weights of each word depending on the graph and using the same aprroach as in \cite{rousseau2013graph}. Finally, we use the TW-IDF measure to calculate the document term matrix.\\

For the dimensionality reduction, we had two choices. Either, we use the Chi-square method or the Latent Semantic Indexing(LSI) in order to get a tractable matrix. Indeed, there are $ $ words in the train corpus. Both methods are already implemented on the $'sci-kit learn'$ library. \\

In the third step, we choose two ways to learn. We compared the SVM and the AdaBoost algorithms. We used cross-validation on the train data to choose between the different parameters. SVM performed naturally better than Adaboost , as did the LSI. We reduced the dimension to $100$ since it yielded the best results.\\

There were two ways to test: either we construct a document term matrix for the train set and the test set separatly, or we could of constructed the matrix for the whole corpus and then divide it into a train matrix and a test one. The last approach is done so as to make sure that words that are not common for the test and train data sets are all taken into account.\\

We state here the results for a directed unweighted graph with a window of size $4$. We reduce the dimension to $100$ and we apply SVM: for the approach where we get the matrices :\\
\begin{itemize}
	 \item separatly: \begin{itemize}
	 	\item Microaveraging \begin{itemize}
	 		\item precision: $0.640475102787$ 
	 		\item recall: $0.640475102787$
	 	\end{itemize}
	 	\item Macroaveraging \begin{itemize}
	 		\item precision: $0.170622860994$
	 		\item recall: $0.203406087815$
	 	\end{itemize}
	 \end{itemize}
	 
	 \item jointly: \begin{itemize}
	 	\item Microaveraging \begin{itemize}
	 		\item precision: $0.667428049338$ 
	 		\item recall: $0.667428049338$
	 	\end{itemize}
	 	\item Macroaveraging \begin{itemize}
	 		\item precision: $0.631236989331$
	 		\item recall: $0.229378369$
	 	\end{itemize}
	 \end{itemize}
\end{itemize}

\end{document}